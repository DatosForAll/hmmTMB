---
title: "hmmTMB technical guide"
author: "Th√©o Michelot, Richard Glennie"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    number_sections: yes
bibliography: refs.bib
vignette: |
  %\VignetteIndexEntry{hmmTMB technical guide} %\VignetteEncoding{UTF-8} %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
  number_sections: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE, error = FALSE, warning = FALSE,
  comment = NA
)
```

```{r load-package, echo = FALSE}
library(hmmTMB)
set.seed(342)
```

# Introduction

The package hmmTMB implements hidden Markov models with flexible formulations for the parameters of the hidden state process and parameters of the observation distributions, including linear, smooth or random effects of covariates. This document provides some technical background on the implementation, and is only intended to users who would like to get an idea of the inner workings of the package. For a more accessible introduction to the package, including example analyses with detailed code, see the other vignette (`hmmTMB user guide').

# Mathematical background

## Hidden Markov models

A hidden Markov model (HMM) is comprised of two random processes:

  - the state process $(S_t)$, defined as a $J$-state Markov chain, such that $S_t \ in \{ 1, 2, \dots, J \}$ at any time $t = 1, 2, \dots$;
  
  - the (possibly multivariate) observation process $(Z_t)$. At each time $t$, the observation $Z_t$ arises from one of $J$ probability distributions, determined by the value $S_t$ of the state process.

The state process is parameterised by an initial distribution $\pi^{(1)}= [\Pr(S_1 = 1), \dots, \Pr(S_1 = J)]$, and by a transition probability matrix
$$
\Gamma = 
\begin{pmatrix}
  \gamma_{11} & \gamma_{12} & \cdots & \gamma_{1J} \\
  \gamma_{21} & \gamma_{22} & \cdots & \gamma_{2J} \\
  \vdots & \vdots & \ddots & \vdots \\
  \gamma_{J1} & \gamma_{J2} & \cdots & \gamma_{JJ} \\
\end{pmatrix},
$$
where the $(i,j)$-th entry is the probability of a transition from state $i$ to state $j$, i.e.,
$$
\gamma_{ij} = \Pr(S_t = j \vert S_t = i).
$$

The observations are typically assumed to arise from some parametric distribution, with one set of parameters for each possible value of the state process, and we can write
$$
p(Z_t = z_t \vert S_t = j) = f_Z(z_t, \theta_j)
$$
where $f_Z$ is the assumed pdf for the observation, and $\theta_j$ is the vector of parameters for state $j$.

The main goal of hmmTMB is to offer the possibility to specify flexible models for the transition probabilities or the state-dependent observation parameters, including fixed and random effects of covariates, and smooth relationships between parameters and covariates using smoothing splines. Here, we only provide a very succinct introduction to HMMs to explain how this is done in the package; for a comprehensive description, see for example @zucchini2016.

## Basis-penaly smoothing splines

Flexible relationships between the model parameters described in the previous section and covariates can be defined using basis-penalty smoothing splines, similarly to generalized additive models (GAMs; @wood2017). In this framework, a parameter $\theta$ (either a transition probability or a parameter of the observation distribution) can be specified at time $t$ by
$$
h(\theta_t) = \beta_0 + f_1(x_{1t}) + f_2(x_{2t}) + \dots,
$$
where $h$ is a link function, $\beta_0$ is an intercept parameter, and the functions $f_1, f_2, \dots$ define the smooth relationships between $\theta_t$ and the covariates $x_{1t}, x_{2t}, \dots$. The smooth functions are written as linear combinations of basis functions,
$$
f_{i} (x) = \sum_{k=1}^K \beta_{ik} \psi_{ik}(x),
$$
where various bases can be chosen (e.g., cubic splines, B-splines). Following standard GAM methodology, the roughness (`wiggliness') of these functions is then penalised in the likelihood of the model to ensure that they are smooth. The penalised log-likelihood is
$$
l_p = \log(L) - \sum_i \lambda_i \beta_i^T S_i \beta_i,
$$
where $L$ is the unpenalised HMM likelihood (e.g.\ computed using the forward algorithm), the $\lambda_i$ are smoothness parameters, and $S_i$ is a known penalty matrix determined by the choice of basis.

The smoothness parameters $\lambda_i$ are not known, and need to be estimated jointly with other model parameters. In hmmTMB, we use the marginal likelihood method; i.e., we treat the basis coefficients as random effects, and we consider the marginal likelihood of the fixed effects $\alpha$ and smoothness parameters $\lambda$,
$$
L(\alpha, \lambda \vert z_1, \dots, z_n) = \int p(z_1, \dots, z_n \vert \alpha, \beta) p(\beta \vert \lambda) d\beta,
$$
where $p(z_1, \dots, z_n \ vert \theta, \beta)$ is the HMM likelihood, and $p(\beta \vert \lambda)$ is a multivariate normal pdf with mean zero and block-diagonal precision matrix with blocks $\lambda_i S_i$.

# Implementation using TMB and mgcv

## Model specification using mgcv

We use the gam function from the package mgcv to create design matrices from the formulas specified for the HMM parameters (including linear effects, basis functions, and random effects), and the penalty matrices for smoothing splines (@wood2017). Users therefore need to use the mgcv syntax for smooth terms and random effects, as described in the [mgcv documentation](https://stat.ethz.ch/R-manual/R-patched/library/mgcv/html/smooth.terms.html). Here, we present a short example to illustrate how gam is used in hmmTMB. Consider the following data frame containing values for two covariates x1 and x2}, and a time series identifier ID},

```{r data, echo = FALSE, message = "hide"}
n <- 100
data <- data.frame(ID = factor(rep(1:4, each = n/4)),
                   x1 = cumsum(rnorm(n, 0, 1)),
                   x2 = cumsum(rnorm(n, 0, 1)))

head(data)
```

Then, consider that we want to specify one of the HMM parameters with the following formula:
``` {r formula}
form <- ~ x1 + s(x2, k = 5, bs = "cc") + s(ID, bs = "re")
```
where x1 has a linear effect, x2 has a smooth effect modelled using cyclic cubic regression splines, and a random normal intercept is included for ID}. We compute the model matrices as follows,
``` {r gam}
# Create smooth object using mgcv
smooth <- gam(formula = update(form, dummy ~ .), 
              data = cbind(dummy = 1, data), 
              fit = FALSE)

# Design matrix
X <- smooth$X

# Number of non-smooth model terms (i.e., fixed effects)
nsdf <- smooth$nsdf

# Design matrix for fixed effects
X_fe <- X[, 1:nsdf, drop = FALSE]

# Design matrix for random effects (including smooth model terms)
X_re <- X[, -(1:nsdf), drop = FALSE]
```

The design matrix for the fixed effects is
``` {r x-fe}
head(X_fe)
```
and the design matrix for the random effects is
```{r x-re}
head(X_re)
```
where the first four columns correspond to the four basis functions for x2}, and the four last columns are dummy indicator variables for ID}. Then, the linear predictor for the corresponding HMM parameter is
``` {r lp, eval = FALSE}
lp <- X_fe %*% coeff_fe + X_re %*% coeff_re
```
where coeff\_fe and coeff\_re are the coefficients for the fixed effects and the random effects, respectively. The HMM parameter (for each data row) is then obtained by applying the inverse link function to this linear predictor.

Similarly, the penalty matrix for the smooth terms can be extracted from the GAM object,
``` {r s-mat}
S <- smooth$S
```

## Model fitting using TMB

We use the R package Template Model Builder (TMB) to implement the marginal likelihood of the model, based on the Laplace approximation to integrate over the random effects (@kristensen2016). Here, we present the general idea for using TMB to evaluate the negative log-likelihood, and to obtain point and uncertainty estimates for the model parameters.

The joint log-likelihood of the fixed and random effects must first be written in C++, following the TMB syntax (for examples, see [the TMB documentation](https://kaskr.github.io/adcomp/examples.html)). For our model, it has two main components:

  - the forward algorithm is used to evaluate the HMM likelihood given all parameters. This part requires the HMM parameters on a time grid, which can be computed based on the model matrices provided by mgcv, as described in the previous section.

  - the log-pdf of the basis coefficients (and other random effects) given the smoothness parameter, $\log p(\beta \vert \lambda)$, obtained as the log of a multivariate normal pdf with block-diagonal precision matrix, where the $i$-th block is $\lambda_i S_i$. The smoothness matrix $S_i$ is provided by mgcv, as described in the previous section.

The negative log-likelihood function (and its gradient) can then be defined in R with the TMB function MakeADFun}, using the argument `random' to specify that the basis coefficients coeff\_re should be treated as random effects. We then use the numerical optimiser optim to perform maximum likelihood estimation of the fixed effect parameters. After optimisation, we use the function sdreport to obtain estimates of the random effect parameters, as well as a joint precision matrix for the fixed and random effects. Posterior samples of all model parameters can be generated from a multivariate normal distribution, where the covariance matrix is the inverse of this precision matrix.

Note that TMB relies on the Laplace approximation to integrate the likelihood over the random effects, i.e.\ the likelihood is approximated by a normal pdf to make the integration tractable. This may result in large errors in cases where the likelihood is very non-normal, e.g., if it is multimodal. HMM likelihoods are known to be multimodal, in particular along the parameters of the observation distributions, and it is not clear how this will affect estimation. Recently, @mcclintock2020random found that TMB performed well in various simulation scenarios, but further investigations will be required to understand this issue better.

# Package structure

We use the object-oriented programming framework of the package R6 (@chang2019) for all data and model objects. The main classes are shown in the table below.

| Class name  | What it is                  | Main attributes           | Example                                       |
|-------------|-----------------------------|---------------------------|-----------------------------------------------|
| Dist        | Probability distribution    | name                      | normal distribution                           |
|             |                             | pdf                       | dnorm                                         |
|             |                             | rng                       | rnorm                                         |
|             |                             | link functions            |                                               |
|             |                             | inverse link functions    |                                               |
| HmmData     | Data set                    | data                      | data frame of observations and covariates     |
| MarkovChain | Markov chain model          | number of states          | 2-state Markov chain                          |
|             |                             | formulas                  | no covariate dependence                       |
|             |                             | Markov chain parameters   | transition probabilities                      |
| Observation | Observation model           | HmmData object            | data frame of observations (z1, z2)           |
|             |                             | list of Dist objects      | list(z1 = "norm", z2 = "gamma")               |
|             |                             | formulas                  | no covariate dependence                       |
|             |                             | observation parameters    | parameters of normal and gamma distributions  |
| Hmm         | Hidden Markov model         | Markov chain object       |                                               |
|             |                             | Observation object        |                                               |
|             |                             | output of optimiser       |                                               |

Each class is defined in a separate R file, which contains all its methods (i.e., the functions that can be applied to an object of that class).
  - Implementation details: make_mat, par_all, obs_probs, coeff_fe, coeff_re, lambda...

## Observation distribution

Distributions for the observation process are created using the Dist class. To define a new distribution, we provide its name (as a string), its probability density/mass function (as a function), the random generator function, and the link functions for its parameters (as named lists of functions). For example, for the normal distribution, we have
```{r dist-def}
dist_norm <- Dist$new(
  name = "norm", 
  pdf = dnorm,
  rng = rnorm,
  link = list(mean = identity, sd = log),
  invlink = list(mean = identity, sd = exp),
  npar = 2
)
```

The Poisson, gamma, normal, beta, and von Mises distributions are included in the package, and more will be implemented in the future.

The functions n2w and w2n transform parameters of the observation distributions from the natural to the working scale and vice-versa. We can verify that applying the two functions successively returns the original parameter values:
```{r norm-test}
# List of parameters (on the natural scale)
par1 <- list(mean = c(0, 5), sd = c(1, 10))

# Transform to working scale
wpar <- dist_norm$n2w(par1)
wpar

# Transform back to natural scale
par2 <- dist_norm$w2n(wpar)
par2
```

## HMM data

Data objects are defined with the HmmData class. An object can be created from a data frame which includes one column for each observed variable and for each covariate. There are special column names: "ID" is used to identify the time series if several are provided, and "time" gives the times of observation. If the times of observations are provided, gaps are automatically filled with NAs to create a obtain a regular time grid.

```{r create-data}
# Create a dummy data set, with two time series
times1 <- seq(as.POSIXct("2020/01/01 00:00:00"), by = "hour", length = 10)
times2 <- seq(as.POSIXct("2020/02/01 00:00:00"), by = "hour", length = 10)
data <- data.frame(ID = rep(c(1, 2), each = 10),
                   x = rnorm(20), 
                   time = c(times1, times2))

# Remove a few rows to create gaps in the data
data <- data[-c(2:3, 7, 15:18),]

# Define HmmData object
data_prep <- HmmData$new(data = data, interval = "hour")

# The gaps have been filled
data_prep$data()
```

## HMM observation model

The class Observation encapsulates the model for the observed variables.

```{r obs-create}
# Create a dummy data set
times <- seq(as.POSIXct("2020/01/01 00:00:00"), by = "hour", length = 100)
data <- data.frame(ID = rep(1, 100),
                   x = rnorm(100), 
                   time = times)
data_prep <- HmmData$new(data = data)

# List of observation distributions
dists <- list(x = dist_norm)

# List of observation parameters
par <- list(x = list(mean = c(0, 0), sd = c(1, 10)))

# Number of states
n_states <- 2

# Create observation process object
obs_process <- Observation$new(data = data_prep, dists = dists, 
                               n_states = n_states, par = par)
```

The parameters on the working scale are calculated when the object is created:
```{r obs-wpar}
obs_process$coeff_fe()
```

The function plot_dist generates a histogram of the observations with the probability density (or mass) function of the specified distribution.
```{r obs-plot}
# Plot histogram and pdf for variable "x"
obs_process$plot_dist(name = "x")
```

# Future work

## Higher priority

 - prepare package for sharing:
   + uniformize names/notation/..., e.g., captilization of class names
   + improve class structure, e.g., groups of methods
   + remove HmmData class if useless, or allow for data frame to be passed instead
   + check that the code is commented well
   + check that the documentation is adequate
   + reduce code redundancy where possible (e.g., make_mat)
   + add error messages (e.g., observations incompatible with distribution)

 - additional observation distributions
    + Weibull
    + log-normal
    + wrapped Cauchy
    + Bernoulli...
    
## Lower priority (easy?)

 - state probabilities (local decoding)

 - pseudo-residuals

 - allow for input of known states (semi-supervised learning)

 - deal with NAs in covariates (linear interpolation? nearest value? error message?)

 - stationary = TRUE/FALSE option in MarkovChain class
 
## Lower priority (difficult?)

 - AIC
   
 - zero inflation
 
 - improve parametrisation of mean of circular distributions (avoid numerical issues around -pi and pi)
 
 - allow for constraints on parameters
    + inequalities, e.g. $\mu_1 < \mu_2$
    + bounds, e.g. $-1 < \mu_1 < 1$ (using custom link function)
    + fixed value, e.g. $\mu_1 = 0$ (using map)

 - obtain starting values for complex models from simpler nested model (e.g. for smooth effects)

 - method "update" similar to glmmTMB, to create a new model from an existing model?
 
# References